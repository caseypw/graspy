{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# K-Means Clustering"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "random.seed(10)"
   ]
  },
  {
   "source": [
    "K-Means Clustering (kclust) is a clustering algorithm that finds the optimal kmeans clustering model by iterating over a range of values and creating a model with the lowest possible silhouette score, as defined in SKlearn [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html).\n",
    "\n",
    "Kmeans clustering is a form of clustering that works to seperate samples into a number of equivariant groups while minimizing the sum of the smallest squared deviations that each sample point has from any of the cluster means. Mathematically, the algorithm is trying to create clusters with small enough means to minimize the following quantity:\n",
    "\n",
    "$$\\sum_{i=1}^{N} \\underset{\\mu_{c}, c \\in C}{\\text{min}}_{}||x_{i} - \\mu_{c}||^{2}$$\n",
    "\n",
    "where $N$ is the number of samples, $\\mu_{c}$ is the mean of cluster $c$, $C$ is the set of all clusters, $x_{i}$ is a sample point, and $|| \\cdot ||$ is the Euclidean distance."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Using KClust on Synthetic Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic data\n",
    "\n",
    "# Dim 1\n",
    "class_1 = np.random.randn(150, 1)\n",
    "class_2 = 2 + np.random.randn(150, 1)\n",
    "dim_1 = np.vstack((class_1, class_2))\n",
    "\n",
    "# Dim 2\n",
    "class_3 = np.random.randn(150, 1)\n",
    "class_4 = 2 + np.random.randn(150, 1)\n",
    "dim_2 = np.vstack((class_3, class_4))\n",
    "\n",
    "X = np.hstack((dim_1, dim_2))\n",
    "\n",
    "# Labels\n",
    "label_1 = np.zeros((150, 1))\n",
    "label_2 = 1 + label_1\n",
    "\n",
    "c = np.vstack((label_1, label_2)).reshape(300,)"
   ]
  },
  {
   "source": [
    "In the existing implementation of KMeans clustering in Sklearn, one has to choose parameters of the model, including number of components, apriori. This can lead to an inaccurate KClust model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# Say user provides inaccurate estimate of number of components\n",
    "kmeans_ = KMeans(3)\n",
    "\n",
    "# Predicted Labels\n",
    "c_hat_kmeans = kmeans_.fit_predict(X)\n",
    "\n",
    "# Function to remap labels for direct comparison\n",
    "def remap_labels(y_true, y_pred):\n",
    "\n",
    "    confusion_mat = confusion_matrix(y_true, y_pred)\n",
    "    row_inds, col_inds = linear_sum_assignment(confusion_mat, maximize=True)\n",
    "    label_map = dict(zip(col_inds, row_inds))\n",
    "    remapped_y_pred = np.vectorize(label_map.get)(y_pred)\n",
    "    \n",
    "    return remapped_y_pred\n",
    "\n",
    "# Remap Predicted labels\n",
    "c_hat_kmeans = remap_labels(c, c_hat_kmeans)"
   ]
  },
  {
   "source": [
    "Our method expands upon the existing Sklearn framework by allowing the user to automatically find the optimal number of clusters and achieve the best clustering possible. The ideal `n_clusters_` that is less than the max value provided by the user is found."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.cluster.kclust import KMeansCluster\n",
    "\n",
    "# Fit model\n",
    "kclust_ = KMeansCluster(max_clusters=3)\n",
    "\n",
    "# Estimated labels\n",
    "c_hat_kclust = kclust_.fit_predict(X,c)\n",
    "\n",
    "# Remap Labels for Color Accuracy\n",
    "c_hat_kclust = remap_labels(c, c_hat_kclust)"
   ]
  },
  {
   "source": [
    "We can plot the clusters and view the varying accuracies"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Synthetic clusters\n",
    "import matplotlib as mp\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_context(\"talk\", font_scale=1.10)\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "\n",
    "# Labelings\n",
    "c_list = ['red', 'green', 'blue']\n",
    "\n",
    "# Plotting Function for Clustering\n",
    "def plot(title_str, c_hat, X):\n",
    "    plt.title(title_str,fontsize=24,fontweight='bold')\n",
    "    max_c = int(np.max(c_hat))\n",
    "    plt.scatter(X[:,0],X[:,1],c=c_hat,cmap=mp.colors.ListedColormap(c_list[0:max_c+1]))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20,5))\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "\n",
    "# True Clustering\n",
    "plt.subplot(1, 3, (1,1))\n",
    "plot('True Clustering', c, X)\n",
    "plt.ylabel('Second Dimension',fontsize=24)\n",
    "\n",
    "# KClust\n",
    "plt.subplot(1, 3, (2,2))\n",
    "plot('KClust Clustering', c_hat_kclust, X)\n",
    "plt.xlabel('First Dimension',fontsize=24)\n",
    "\n",
    "# SKlearn\n",
    "plt.subplot(1, 3, (3,3))\n",
    "plot('SKlearn Clustering', c_hat_kmeans, X)\n",
    "\n",
    "plt.show()"
   ]
  }
 ]
}